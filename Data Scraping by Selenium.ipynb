{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, base_url, path, company, filename):\n",
    "        self.filename = filename\n",
    "        self.base_url = base_url\n",
    "        self.company = company\n",
    "        self.driver = webdriver.Chrome(path)\n",
    "        self.links = []\n",
    "\n",
    "    def run(self):\n",
    "        self.driver.get(self.base_url)\n",
    "        self.search_company()\n",
    "        self.get_all_reviews()\n",
    "        self.reach_links()\n",
    "\n",
    "    def reach_links(self):\n",
    "        for link in self.links:\n",
    "            self.driver.get(link)\n",
    "            time.sleep(1)\n",
    "            self.get_data()\n",
    "\n",
    "    def get_data(self):\n",
    "        lst = [self.driver.find_element_by_class_name(\"_1xPYIUfA9IwtVyBsOt_SaR\").text,\n",
    "               self.driver.find_element_by_class_name(\"_1_dikBfyioZMrCoMA4C9hZ\").text]\n",
    "        try:\n",
    "            lst.append(self.driver.find_element_by_id(\"years-worked-with\").text)\n",
    "        except:\n",
    "            lst.append(\"None\")\n",
    "        try:\n",
    "            lst.append(self.driver.find_element_by_id(\"work-location\").text)\n",
    "        except:\n",
    "            lst.append(\"None\")\n",
    "        stars = self.driver.find_elements_by_class_name(\"OX0_TZZSlhMhIywgR8jko\")\n",
    "        lst.append(stars[0].text)\n",
    "        lst.append(stars[2].text)\n",
    "        lst.append(stars[4].text)\n",
    "        lst.append(stars[1].text)\n",
    "        lst.append(stars[3].text)\n",
    "        lst.append(stars[5].text)\n",
    "        lst.append(self.driver.find_element_by_class_name(\"Tlh9F04dzRFo78gJPlhMM\").text)\n",
    "        lst.append(self.driver.find_element_by_class_name(\"_3MyALCcnLdxQbK6kunFzgk\").text)\n",
    "        lst.append(self.driver.find_element_by_id(\"good-review\").text)\n",
    "        lst.append(self.driver.find_element_by_id(\"challange-review\").text)\n",
    "        divs = self.driver.find_elements_by_class_name(\"_2N4PqnlVAzHqUH2g5yZLn5\")\n",
    "        lst.append(divs[0].text)\n",
    "        lst.append(divs[1].text)\n",
    "\n",
    "        self.append_data(lst)\n",
    "\n",
    "    def append_data(self, data):\n",
    "        with open(self.filename, 'a') as f:\n",
    "            f.write(\"\\n\")\n",
    "            for d in data:\n",
    "                try:\n",
    "                    f.write(d + \",\")\n",
    "                except:\n",
    "                    f.write(\"None\" + \",\")\n",
    "\n",
    "    def get_all_reviews(self):\n",
    "        pages = self.get_pages_number()\n",
    "        for page in range(pages):\n",
    "            self.get_review_links()\n",
    "            if page + 1 != pages:\n",
    "                self.go_to_next_page()\n",
    "\n",
    "    def go_to_next_page(self):\n",
    "        self.driver.find_element_by_class_name(\"_1obKPTnJFYAW7RWRamBIS5\").click()\n",
    "\n",
    "    def get_pages_number(self):\n",
    "        time.sleep(2)\n",
    "        div = self.driver.find_element_by_class_name(\"RZ46YESzIdDEUyK1AEEUQ\")\n",
    "        spans = div.find_elements_by_tag_name(\"span\")\n",
    "        pages = int(spans[2].text.split(\" \")[-1])\n",
    "        return pages\n",
    "\n",
    "    def get_review_links(self):\n",
    "        time.sleep(2)\n",
    "        parents = self.driver.find_elements_by_class_name(\"_3MyALCcnLdxQbK6kunFzgk\")\n",
    "        for parent in parents:\n",
    "            a = parent.find_element_by_tag_name(\"a\")\n",
    "            self.links.append(a.get_attribute(\"href\"))\n",
    "        return\n",
    "\n",
    "    def search_company(self):\n",
    "        search_input = self.driver.find_element_by_id(\"companySearch\")\n",
    "        search_input.send_keys(self.company)\n",
    "        search_input.send_keys(Keys.ENTER)\n",
    "        time.sleep(2)\n",
    "        self.driver.find_element_by_class_name(\"tNpZ-r8HSFPRZ6NJvAkbQ\").click()\n",
    "        time.sleep(2)\n",
    "        self.driver.find_element_by_class_name(\"_3Z7Y99Bn3qT4N_dKKyG0ka\").click()\n",
    "        return\n",
    "\n",
    "\n",
    "def make_csv_file(filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\n",
    "            \"Job title,review data,duration,home location,benefits & perks,work/life balance,management,career development,working environment,diversity & equal opportunity,overall,review title,the good things,the challenges,salary rated,employer_recommendation\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    PATH = \"chromedriver.exe\"\n",
    "    BASE_URL = \"https://www.seek.com.au/companies\"\n",
    "    COMPANY = \"H&R BLOCK\"  # Here comes company name to search for\n",
    "    FILENAME = \"data.csv\"  # The filename of data\n",
    "    make_csv_file(FILENAME)\n",
    "    Scraper(BASE_URL, PATH, COMPANY, FILENAME).run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
